{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\"> K-Nearest Neighbors (Canser Dataset) </h1>\n",
    "    <h3 align=\"center\"><a href=\"https://github.com/amirhosein-ziaei\">Amirhosein Ziaei</a></h3>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is K-Nearest Neighbor (KNN)?\n",
    "\n",
    "K-Nearest Neighbors, or **KNN** for short, is one of the simplest machine learning algorithms and is used in a wide array of institutions. KNN is a `non-parametric`, `lazy learning` algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When we say a technique is non-parametric, it means that it does not make any assumptions about the underlying data. In other words, it makes its selection based off of the proximity to other data points regardless of what feature the numerical values represent. \n",
    "\n",
    "* Being a lazy learning algorithm implies that there is little to no training phase. Therefore, we can immediately classify new data points as they present themselves.\n",
    "\n",
    "> K-NN is a lazy learner because it doesn’t learn a discriminative function from the training data but “memorizes” the training dataset instead.\n",
    "For example, the logistic regression algorithm learns its model weights (parameters) during training time. In contrast, there is no training time in K-NN.\n",
    "\n",
    "**To summarize: An eager learner has a model fitting or training step. A lazy learner does not have a training phase.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm...\n",
    "\n",
    "1.Initialize the K value.\n",
    "\n",
    "2.Calculate the distance between test input and K trained nearest neighbors.\n",
    "\n",
    "3.Check class categories of nearest neighbors and determine the type in which test input falls.\n",
    "\n",
    "4.Classification will be done by taking the majority of votes.\n",
    "\n",
    "5.Return the class category."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some pros and cons of KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pros:\n",
    "\n",
    "* No assumptions about data\n",
    "* Simple algorithm — easy to understand\n",
    "* Can be used for classification and regression\n",
    "\n",
    "> Cons:\n",
    "\n",
    "* High memory requirement — All of the training data must be present in memory in order to calculate the closest K neighbors\n",
    "* Sensitive to irrelevant features\n",
    "* Sensitive to the scale of the data since we’re computing the distance to the closest K points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Importing Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
